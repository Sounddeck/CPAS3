import logging
import os
import uuid
import threading
from typing import List, Dict, Optional, Any, Type

# LangChain components
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import PromptTemplate # Correct import if using directly
from langchain_core.tools import BaseTool
from langchain_core.language_models import BaseChatModel

# Attempt to import specific LLM providers, fall back if necessary
try:
    from langchain_ollama.chat_models import ChatOllama
except ImportError:
    logging.warning("langchain_ollama not found, falling back to langchain_community.ChatOllama.")
    try:
        from langchain_community.chat_models import ChatOllama
    except ImportError:
        logging.error("ChatOllama not found in langchain_community either. Ollama support disabled.")
        ChatOllama = None

try:
    # Conditional import for OpenAI if needed in the future
    # from langchain_openai import ChatOpenAI
    pass
except ImportError:
    logging.warning("langchain_openai not found. OpenAI support disabled.")
    # ChatOpenAI = None


# Local imports
from .agent_instance import AgentInstance
from .models import AgentStatus, AgentTask, AgentConfig # Import AgentConfig
from .task_queue import TaskQueue
from .persistence.agent_store import AgentStore
from ..utils.config_manager import ConfigManager
from ..utils.history_manager import HistoryManager
from ..tools.tool_manager import ToolManager
from ..tools.file_system_tool import FileSystemTool # Example tool import
from .monitoring.resource_monitor import ResourceMonitor
from .monitoring.performance_tracker import PerformanceTracker

# Import the shared signal emitter
try:
    from ..ui.signal_emitter import signal_emitter
    UI_AVAILABLE = True
except ImportError:
    UI_AVAILABLE = False
    # Dummy emitter if UI is not available
    class DummySignalEmitter:
        def __getattr__(self, name):
            class DummySignal:
                def emit(self, *args, **kwargs): pass
            return DummySignal()
    signal_emitter = DummySignalEmitter()
    logging.info("AgentManager running without UI signal emitter.")


logger = logging.getLogger(__name__)

class AgentManager:
    """
    Manages the lifecycle and task assignment for multiple AgentInstances.
    """
    def __init__(self, config_manager: ConfigManager):
        logger.info("Initializing AgentManager...")
        self.config_manager = config_manager
        self._task_queue = TaskQueue()
        self._agent_store = AgentStore(config_dir=config_manager.config_dir)
        self._history_manager = HistoryManager(save_callback=self._agent_store.save_agent_history)
        self._resource_monitor = ResourceMonitor()
        self._performance_tracker = PerformanceTracker()
        self.agents: Dict[str, AgentInstance] = {}
        self._agent_threads: Dict[str, threading.Thread] = {} # Keep track of threads if needed
        self._lock = threading.Lock() # For thread-safe access to self.agents

        # --- LLM and Tool Initialization ---
        self.llm = self._initialize_llm()
        self.tool_manager = self._initialize_tool_manager()
        self.available_tools = self.tool_manager.get_tools()

        # --- Default Agent Configuration ---
        # Load default config - adjust path/logic as needed
        self.default_agent_config = self._load_default_agent_config()

        # --- Agent Loading and Initialization ---
        self.load_agents() # Load existing agents from persistence

        # --- Monitoring ---
        self._resource_monitor.start() # Start resource monitoring

        logger.info("AgentManager initialized.")

    def _load_default_agent_config(self) -> AgentConfig:
        """Loads the default agent configuration."""
        # Example: Load from a file or use hardcoded defaults
        # In a real app, load from config_manager or a dedicated config file
        default_settings = {
            "max_iterations": 10,
            "temperature": 0.7,
            "default_prompt": "You are a helpful assistant.",
            # Add other relevant default settings
        }
        try:
            config_data = self.config_manager.get("agent_defaults", default_settings)
            return AgentConfig(**config_data)
        except Exception as e:
            logger.error(f"Failed to load/parse default agent config: {e}. Using basic defaults.", exc_info=True)
            return AgentConfig() # Return default Pydantic model

    def _initialize_llm(self) -> Optional[BaseChatModel]:
        """Initializes the language model based on configuration."""
        llm_provider = self.config_manager.get("llm_provider", "ollama") # Default to ollama
        llm_model_name = self.config_manager.get("llm_model")
        api_key = self.config_manager.get("llm_api_key") # Optional
        llm_base_url = self.config_manager.get("llm_base_url") # Optional (for Ollama, etc.)

        logger.info(f"Attempting to initialize LLM provider: {llm_provider}")

        if llm_provider == "ollama":
            if not ChatOllama:
                logger.error("Ollama provider selected but ChatOllama class is not available.")
                return None
            if not llm_model_name:
                llm_model_name = "mistral:7b" # Default Ollama model
                logger.warning(f"Ollama model not specified, defaulting to {llm_model_name}.")
            if not llm_base_url:
                 llm_base_url = "http://localhost:11434" # Default Ollama URL
                 logger.info(f"Ollama base_url not specified, defaulting to {llm_base_url}")

            try:
                llm = ChatOllama(model=llm_model_name, base_url=llm_base_url)
                logger.info(f"Initialized ChatOllama with model '{llm_model_name}' at {llm_base_url}")
                return llm
            except Exception as e:
                logger.error(f"Failed to initialize ChatOllama: {e}", exc_info=True)
                return None

        elif llm_provider == "openai":
             # Placeholder for OpenAI initialization
             # if not ChatOpenAI:
             #      logger.error("OpenAI provider selected but ChatOpenAI class is not available.")
             #      return None
             # if not llm_model_name:
             #      llm_model_name = "gpt-3.5-turbo"
             #      logger.warning(f"OpenAI model not specified, defaulting to {llm_model_name}.")
             # if not api_key:
             #      logger.error("OpenAI provider selected but API key is missing in config.")
             #      return None
             # try:
             #      llm = ChatOpenAI(model=llm_model_name, api_key=api_key)
             #      logger.info(f"Initialized ChatOpenAI with model '{llm_model_name}'.")
             #      return llm
             # except Exception as e:
             #      logger.error(f"Failed to initialize ChatOpenAI: {e}", exc_info=True)
             #      return None
             logger.warning("OpenAI provider selected but implementation is currently disabled.")
             return None

        else:
            logger.error(f"Unsupported LLM provider configured: {llm_provider}")
            return None

    def _initialize_tool_manager(self) -> ToolManager:
        """Initializes the ToolManager with available tools."""
        # Define base workspace directory for tools that need it
        workspace_base_dir = os.path.join(PROJECT_ROOT, "modules", "agent_workspace")
        os.makedirs(workspace_base_dir, exist_ok=True)
        logger.info(f"ToolManager workspace base directory set to: {workspace_base_dir}")

        # List of tool classes to register
        # Add more tool classes here as they are created
        tool_classes: List[Type[BaseTool]] = [
            FileSystemTool,
            # Example: WebSearchTool, DatabaseTool, etc.
        ]

        tool_manager = ToolManager(tool_classes=tool_classes, workspace_dir=workspace_base_dir)
        logger.info(f"Initialized tools via ToolManager: {list(tool_manager.get_tools().keys())}")
        return tool_manager


    def _create_agent_executor(self, tools: List[BaseTool]) -> Optional[AgentExecutor]:
        """Creates a LangChain AgentExecutor."""
        if not self.llm:
            logger.error("Cannot create AgentExecutor: LLM is not initialized.")
            return None
        try:
            # Pull the ReAct prompt
            # TODO: Make prompt configurable
            prompt = PromptTemplate.from_template(
                """Answer the following questions as best you can. You have access to the following tools:

                {tools}

                Use the following format:

                Question: the input question you must answer
                Thought: you should always think about what to do
                Action: the action to take, should be one of [{tool_names}]
                Action Input: the input to the action
                Observation: the result of the action
                ... (this Thought/Action/Action Input/Observation can repeat N times)
                Thought: I now know the final answer
                Final Answer: the final answer to the original input question

                Begin!

                Question: {input}
                Thought:{agent_scratchpad}"""
            )
            # Alternative: Load from Hub
            # from langchain import hub
            # prompt = hub.pull("hwchase17/react") # Example ReAct prompt

            logger.info("Loaded ReAct prompt 'hwchase17/react' from LangChain Hub.") # Assuming Hub for now

            # Create the ReAct agent
            agent = create_react_agent(self.llm, tools, prompt)

            # Create the AgentExecutor
            agent_executor = AgentExecutor(
                agent=agent,
                tools=tools,
                verbose=True, # Set to True for detailed logs during execution
                handle_parsing_errors=True, # Attempt to recover from tool output parsing errors
                max_iterations=self.default_agent_config.max_iterations # Use default config
                )
            logger.info(f"Created AgentExecutor with tools: {[tool.name for tool in tools]}")
            return agent_executor

        except Exception as e:
            logger.error(f"Failed to create AgentExecutor: {e}", exc_info=True)
            return None


    def create_agent(
        self,
        name: str,
        config_overrides: Optional[Dict[str, Any]] = None,
        auto_start: bool = True
        ) -> Optional[AgentInstance]:
        """Creates, stores, and starts a new AgentInstance."""
        if not self.llm:
             logger.error("Cannot create agent: LLM is not initialized.")
             return None

        logger.info(f"Creating new agent: '{name}'")
        agent_id = uuid.uuid4().hex
        final_config = self.default_agent_config.model_copy(deep=True) # Start with default

        # Apply overrides if provided
        if config_overrides:
            try:
                # Create a new config instance with overrides applied
                # This ensures validation happens
                override_data = final_config.model_dump()
                override_data.update(config_overrides)
                final_config = AgentConfig(**override_data)
                logger.info(f"Applied config overrides for new agent {agent_id[:8]}")
            except Exception as e:
                logger.error(f"Invalid config overrides provided for agent '{name}': {e}. Using defaults.", exc_info=True)
                # Stick with the original default_agent_config if overrides fail validation
                final_config = self.default_agent_config.model_copy(deep=True)


        # TODO: Allow specifying specific tools per agent?
        agent_tools = list(self.available_tools.values())
        agent_executor = self._create_agent_executor(agent_tools)
        if not agent_executor:
             logger.error(f"Failed to create AgentExecutor for agent '{name}'. Cannot create agent.")
             return None

        try:
            agent_instance = AgentInstance(
                agent_id=agent_id,
                name=name,
                config=final_config, # Pass the validated AgentConfig object
                llm=self.llm,
                tools=agent_tools,
                agent_executor=agent_executor,
                task_queue=self._task_queue,
                agent_store=self._agent_store,
                history_manager=self._history_manager,
                initial_status=AgentStatus.IDLE,
                # Pass the callback method
                on_stop_callback=self._handle_agent_thread_stop
            )
        except Exception as e:
             logger.error(f"Failed to initialize AgentInstance for '{name}': {e}", exc_info=True)
             return None


        with self._lock:
            self.agents[agent_id] = agent_instance

        # Persist initial state and add to manifest
        try:
            self._agent_store.save_agent_state(agent_id, agent_instance.get_state())
            self._agent_store.add_agent_to_manifest(agent_id, name)
        except Exception as e:
             logger.error(f"Failed to save initial state or update manifest for agent {agent_id[:8]}: {e}", exc_info=True)
             # Proceed with agent creation but log the persistence error


        logger.info(f"Agent '{name}' (ID: {agent_id[:8]}) created successfully.")
        # Emit signal for UI update (send state dictionary)
        signal_emitter.agent_created.emit(agent_instance.get_state())

        if auto_start:
            logger.info(f"Auto-starting new agent {agent_id[:8]}.")
            try:
                 agent_instance.start()
                 # agent_instance.start() handles status update and logging
            except Exception as e:
                 logger.error(f"Failed to start agent instance for '{name}' (post-creation): {e}", exc_info=True)
                 # Set status to ERROR if start fails immediately
                 agent_instance._set_status(AgentStatus.ERROR)


        return agent_instance

    def load_agents(self):
        """Loads agent states from the AgentStore and recreates instances."""
        if not self.llm:
             logger.error("Cannot load agents: LLM is not initialized.")
             return

        logger.info("Loading agents from store...")
        try:
            agent_states = self._agent_store.get_all_agent_states()
            if not agent_states:
                 logger.info("No existing agent states found to load.")
                 return

            logger.info(f"Attempting to load state for {len(agent_states)} agents listed in manifest...")
            loaded_count = 0
            for agent_id, state_data in agent_states.items():
                if not state_data:
                     logger.warning(f"No state data found for agent ID {agent_id[:8]} listed in manifest. Skipping.")
                     continue
                if agent_id in self.agents:
                     logger.warning(f"Agent {agent_id[:8]} already exists in memory. Skipping loading from state.")
                     continue

                # TODO: Allow specifying tools per agent during loading?
                agent_tools = list(self.available_tools.values())
                agent_executor = self._create_agent_executor(agent_tools)
                if not agent_executor:
                     logger.error(f"Failed to create AgentExecutor for loaded agent {agent_id[:8]}. Cannot load agent.")
                     continue

                try:
                    instance = AgentInstance.from_state(
                        state_data=state_data,
                        llm=self.llm,
                        tools=agent_tools,
                        agent_executor=agent_executor,
                        task_queue=self._task_queue,
                        agent_store=self._agent_store,
                        history_manager=self._history_manager,
                        # Pass the callback method
                        on_stop_callback=self._handle_agent_thread_stop
                    )
                    if instance:
                        with self._lock:
                            self.agents[agent_id] = instance
                        loaded_count += 1
                        logger.info(f"Agent '{instance.name}' (ID: {agent_id[:8]}) loaded successfully.")

                        # *** START AGENT IF NOT STOPPED/ERROR ***
                        if instance.status not in [AgentStatus.STOPPED, AgentStatus.ERROR]:
                             logger.info(f"Auto-starting loaded agent {agent_id[:8]} with status {instance.status.name}...")
                             try:
                                  instance.start()
                             except Exception as e:
                                  logger.error(f"Failed to auto-start loaded agent {agent_id[:8]}: {e}", exc_info=True)
                                  instance._set_status(AgentStatus.ERROR) # Set to error if start fails
                        else:
                             logger.info(f"Agent {agent_id[:8]} loaded with status {instance.status.name}, not auto-starting.")

                    else:
                         logger.error(f"Failed to recreate agent instance from state for ID {agent_id[:8]}.")
                         # Optionally: Attempt recovery or mark as errored in manifest?
                except Exception as e:
                     logger.error(f"Error loading agent {agent_id[:8]} from state: {e}", exc_info=True)

            logger.info(f"Finished loading {loaded_count} agents.")
        except Exception as e:
            logger.error(f"Failed to load agents from store: {e}", exc_info=True)

    def remove_agent(self, agent_id: str):
        """Stops, removes, and cleans up an agent."""
        logger.info(f"Removing agent {agent_id[:8]}...")
        instance = self.get_agent(agent_id)
        if not instance:
            logger.warning(f"Agent {agent_id[:8]} not found for removal.")
            return

        # 1. Stop the agent's execution thread
        try:
            instance.stop() # Signal the agent to stop
            # Wait for thread to finish? AgentInstance cleanup might handle join.
            # Consider adding a timeout join here if needed.
        except Exception as e:
            logger.error(f"Error signaling stop for agent {agent_id[:8]}: {e}", exc_info=True)

        # 2. Perform agent cleanup (joins thread if still running)
        try:
            instance.cleanup()
        except Exception as e:
            logger.error(f"Error during cleanup for agent {agent_id[:8]}: {e}", exc_info=True)

        # 3. Remove from active agents dictionary
        with self._lock:
            if agent_id in self.agents:
                del self.agents[agent_id]
            if agent_id in self._agent_threads: # If tracking threads separately
                 del self._agent_threads[agent_id]

        # 4. Remove from persistence
        try:
            self._agent_store.remove_agent_state(agent_id)
            self._agent_store.remove_agent_history(agent_id)
            self._agent_store.remove_agent_from_manifest(agent_id)
            logger.info(f"Removed agent {agent_id[:8]} state and manifest entry.")
        except Exception as e:
            logger.error(f"Error removing agent {agent_id[:8]} from store: {e}", exc_info=True)

        logger.info(f"Agent {agent_id[:8]} removed.")
        # Emit signal for UI update
        signal_emitter.agent_removed.emit(agent_id)


    def get_agent(self, agent_id: str) -> Optional[AgentInstance]:
        """Retrieves an agent instance by ID."""
        with self._lock:
            return self.agents.get(agent_id)

    def get_all_agents(self) -> List[AgentInstance]:
        """Returns a list of all current agent instances."""
        with self._lock:
            return list(self.agents.values())

    def assign_task(self, task: AgentTask) -> bool:
        """Adds a task to the central queue."""
        try:
            self._task_queue.put(task)
            logger.info(f"Task {task.task_id[:8]} added to queue. Description: '{task.description[:50]}...'")
            # Emit signal that a task was created/queued
            signal_emitter.task_created.emit(task.to_dict())
            # Emit signal that queue content changed (send list of task dicts?)
            # self.emit_task_queue_update() # Consider adding this helper
            return True
        except Exception as e:
            logger.error(f"Failed to add task {task.task_id[:8]} to queue: {e}", exc_info=True)
            return False

    # --- Agent Lifecycle Callbacks ---
    def _handle_agent_thread_stop(self, agent_id: str):
         """Callback executed when an agent's execution thread finishes."""
         logger.info(f"Manager notified: Agent {agent_id[:8]}'s execution thread has stopped.")
         # Perform any necessary cleanup or state management related to the thread stopping
         with self._lock:
              if agent_id in self._agent_threads:
                   del self._agent_threads[agent_id] # Remove from active thread tracking

         # Check agent status - if it stopped unexpectedly, maybe set to ERROR?
         agent = self.get_agent(agent_id)
         if agent and agent.status not in [AgentStatus.STOPPED, AgentStatus.ERROR]:
              logger.warning(f"Agent {agent_id[:8]} thread stopped unexpectedly while status was {agent.status.name}. Setting status to ERROR.")
              agent._set_status(AgentStatus.ERROR)


    # --- Shutdown ---
    def shutdown(self):
        """Shuts down all agents and monitoring."""
        logger.info("Shutting down AgentManager...")

        # Stop monitoring first
        self._resource_monitor.stop()

        # Signal all agents to stop
        agents_to_stop = self.get_all_agents()
        logger.info(f"Stopping {len(agents_to_stop)} agents...")
        for agent in agents_to_stop:
            try:
                 logger.info(f"Requesting stop for agent {agent.id[:8]}...")
                 agent.stop()
            except Exception as e:
                 logger.error(f"Error signaling stop for agent {agent.id[:8]}: {e}", exc_info=True)

        # Wait for agent threads to finish (optional, relies on agent.cleanup)
        # for agent in agents_to_stop:
        #     try:
        #         agent.cleanup() # cleanup should join the thread
        #     except Exception as e:
        #         logger.error(f"Error during cleanup for agent {agent.id[:8]} during shutdown: {e}", exc_info=True)

        # Add a final check/join with timeout?
        # active_threads = [t for t in self._agent_threads.values() if t.is_alive()]
        # timeout_join = 5.0
        # for thread in active_threads:
        #      thread.join(timeout_join)
        #      if thread.is_alive():
        #           logger.warning(f"Agent thread {thread.name} did not stop cleanly after {timeout_join}s.")


        # Signal task queue to stop (e.g., by putting None markers if needed)
        # self._task_queue.stop() # If TaskQueue has a specific stop mechanism

        logger.info("AgentManager shutdown complete.")

    # --- Internet Access Question ---
    # Regarding the user's question:
    # The current CPAS setup, primarily using the `file_system_tool` and a local Ollama LLM,
    # does *not* require or inherently use internet access for its core operations.
    # If you were to add a tool specifically designed for web searching (like using DuckDuckGo,
    # Google Search, etc. via LangChain integrations), then *that specific tool* would require
    # internet connectivity for the agent using it. The LLM itself (Ollama) runs locally.
